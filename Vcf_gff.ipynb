{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dany-gaga/DGE_analysis/blob/main/Vcf_gff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqNEUueoPG"
      },
      "source": [
        "# **SNPs_Implies**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWF3T1pYfJCB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql7TUP4uz3i5",
        "outputId": "b7fbf566-e98b-4619-c62d-01927868a1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# run this code to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj33llMg-2vV",
        "outputId": "3a2d59b6-e003-4bae-fb76-117f0771724b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gffpandas in /usr/local/lib/python3.10/dist-packages (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gffpandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB-N5XCo-92E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import gffpandas.gffpandas as gffpd\n",
        "import itertools\n",
        "from itertools import chain\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HtFj69LCBjh"
      },
      "outputs": [],
      "source": [
        "#### convert a gff file into a pandas dataframe\n",
        "\n",
        "def gff_to_dataframe(file, output):\n",
        "    \"\"\"\n",
        "    This is a function that takes a file name or path and the name of the\n",
        "    final output to be generated as input\n",
        "    \"\"\"\n",
        "    gff_file = gffpd.read_gff3(file)\n",
        "    gff_file.to_csv(output)\n",
        "\n",
        "# gff_to_dataframe('VectorBase-48_AgambiaePEST.gff', 'g.csv')\n",
        "\n",
        "####\n",
        "\n",
        "def subset_dataframe(file, sep = None):\n",
        "    \"\"\" This function takes as input,\n",
        "    a file path and optionaly a seperator, it can be\n",
        "    '\\t', ';', ','. the default being the latter\n",
        "    \"\"\"\n",
        "    file_to_subset = pd.read_csv(file, sep=sep)\n",
        "    # the values of the first column here is used to subset the data frame\n",
        "    col_names = list(set(list(file_to_subset.iloc[:,0])))\n",
        "    for col in col_names:\n",
        "        t = file_to_subset[file_to_subset.iloc[:,0] == col]\n",
        "        # here we construct the file names based on the original name with the subsetting string\n",
        "        t.to_csv(file + str(col) + \".csv\", index = False)\n",
        "\n",
        "####\n",
        "\n",
        "def list_of_columns(file, start= None, end=None):\n",
        "    \"\"\"\n",
        "    This functions takes as input a file name,\n",
        "    names of columns to be later combined\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for col in (file[start], file[end]):\n",
        "        col1 = list(col)\n",
        "        output.append(col1)\n",
        "    return(output)\n",
        "\n",
        "def merge_lists(list1, list2, list3=None):\n",
        "    \"\"\"\n",
        "    This function merge into one same list\n",
        "    elements from two or three different list\n",
        "    I\"\"\"\n",
        "    if list3 != None:\n",
        "        merged_list = [(list1[i], list2[i], list3[i]) for i in range(0, len(list1))]\n",
        "    else:\n",
        "        merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))]\n",
        "    return merged_list\n",
        "\n",
        "###\n",
        "\n",
        "def merging_vcf_gff(path_vcf, path_gff, types = 'type', the_type='CDS', pos = 'POS', start= 'start', end= 'end'):\n",
        "\n",
        "    \"\"\"\n",
        "    This function takes in multiple input.\n",
        "    path_vcf = folder in which is located the vcf files\n",
        "    path_gff = folder in which is located the gff files\n",
        "\n",
        "    types = type as default, it is the name of the column where the types (genes, cds, intron) are filled.\n",
        "    the_type= CDS as default. It make you specify on which type you want the merging to be done\n",
        "    pos = POS as default. It is the column name for POS in a vcf file\n",
        "    start = start as default. It is the column name for the start of a region in the gff file\n",
        "    end = end as default. It is the column name for the end of a region in the gff file\n",
        "    \"\"\"\n",
        "\n",
        "    # get path to retrieve the different csv file and sort them all\n",
        "    vcfs_files = sorted( filter( os.path.isfile, glob.glob(path_vcf + \"/*.csv\")), reverse=True)\n",
        "    gffs_files = sorted( filter( os.path.isfile, glob.glob(path_gff + \"/*.csv\")), reverse=True)\n",
        "\n",
        "    # create a list of list for both path\n",
        "    vcf_gff = [vcfs_files, gffs_files]\n",
        "    # merge files in each lists. The chromosome should match in both the vcf and the gff files\n",
        "    vgfff = merge_lists(vcf_gff[0], vcf_gff[1])\n",
        "\n",
        "    # from each tuple present in the merged list,\n",
        "    # the files will be read\n",
        "    for vcf1, gff1 in vgfff:\n",
        "\n",
        "        vcf = pd.read_csv(vcf1, sep=',')\n",
        "        gff = pd.read_csv(gff1, sep=',')\n",
        "\n",
        "        # here the types chosen will be used to subset the gff file\n",
        "        gff = (gff[gff[types] == the_type]).drop_duplicates(subset=['start','end'], keep='first')\n",
        "        # a list of column names from the vcf and the gff file will be made into one list\n",
        "        col_names = list(chain.from_iterable(list([vcf.columns, gff.columns])))\n",
        "        # using the function list_of_columns two list containing each start and end positions will be stored\n",
        "        cg = list_of_columns(gff, start=start, end=end)\n",
        "        # the merged list function will be used to merged both lists\n",
        "        col_gff = merge_lists(cg[0], cg[1])\n",
        "\n",
        "        both_file =[] # this stores in arrays containg matching line in both the vcf and the gff\n",
        "        for v in list((vcf[pos])):\n",
        "            v1 = vcf.loc[vcf[pos] == v].values\n",
        "            for s,e in col_gff:\n",
        "                if s <= v <= e:\n",
        "                    se = gff.loc[(gff[start] == s) & (gff[end] == e)].values\n",
        "                    break # the break statement here stop the loop once it finda a corresponding line in the gff file\n",
        "                else:\n",
        "                    se = np.array([[None] * len(gff.columns)]) # else, it continues and fill the arrays with none\n",
        "\n",
        "            vcfgff = np.hstack((v1, se)) # here arrays are merged together following the direction vcf + gff\n",
        "\n",
        "            both_file.append(vcfgff)\n",
        "\n",
        "        v_g = pd.DataFrame(np.concatenate(both_file)) # A data frame is constructed\n",
        "        v_g.columns = col_names # using the columns names stored previously, it append it to the dataframe\n",
        "        v_g['ID']= v_g.attributes.str.slice(3, 13) # can be changed based gene ID length\n",
        "        #vcfgff['chromosome']= vcfgff['#CHROM'].str[7::1] good to know\n",
        "        v_g['chrom_pos'] = v_g['#CHROM'].astype(str).str.cat(v_g.POS.astype(str), sep=':')\n",
        "        v_g = (v_g[v_g[types] == the_type])\n",
        "        v_g.to_csv(vcf1 + \".csv\", index = False) # resulting files are saved in the output folder\n",
        "\n",
        "# Get CSV files list from a folder\n",
        "# path = './gffs/'\n",
        "# path1 = './vcfs/'\n",
        "# merging_vcf_gff(path1, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZRU7GCM_ET8"
      },
      "outputs": [],
      "source": [
        "fn = '/content/gdrive/MyDrive/vcf_gff/VectorBase-48_AgambiaePEST.gff'\n",
        "gff_to_dataframe(fn, 'agam_annotation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWyOiyZyAa0g"
      },
      "outputs": [],
      "source": [
        "# vcf have been previoulsy converted to csv\n",
        "# vcf-to-tab < all_vcf.vcf >  all_vcf.csv\n",
        "\n",
        "vcf = '/content/gdrive/MyDrive/vcf_gff/all_vcf.csv'\n",
        "gff = '/content/gdrive/MyDrive/vcf_gff/agam_annotation.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2IdKp3vDZSo"
      },
      "outputs": [],
      "source": [
        "# make three distinct folder for the vcf and gff files to be subsetted and one for the merged files\n",
        "vcfs = \"/content/gdrive/MyDrive/vcf_gff/vcfs\"\n",
        "gffs = \"/content/gdrive/MyDrive/vcf_gff/gffs\"\n",
        "v_g = \"/content/gdrive/MyDrive/vcf_gff/v_g\"\n",
        "per_samples = \"/content/gdrive/MyDrive/vcf_gff/per_samples\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH7QY3um2fPh"
      },
      "outputs": [],
      "source": [
        "os.mkdir(vcfs)\n",
        "os.mkdir(gffs)\n",
        "os.mkdir(v_g)\n",
        "os.mkdir(per_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQXVQxdBNNg-"
      },
      "outputs": [],
      "source": [
        "subset_dataframe(gff, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWSlyRS2OAbs"
      },
      "outputs": [],
      "source": [
        "subset_dataframe(vcf, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmAq9PipUtPc"
      },
      "outputs": [],
      "source": [
        "!mv agam_annotation.csvAgam* /content/gdrive/MyDrive/vcf_gff/gffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04vLX5AoU8aN"
      },
      "outputs": [],
      "source": [
        "!mv all_vcf.csvAgam* /content/gdrive/MyDrive/vcf_gff/vcfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cysWf-sNVYvC"
      },
      "outputs": [],
      "source": [
        "# here, make sure you do not delete the main vcf file\n",
        "!rm all_vcf.csvAA*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSt0zRjIK_QP"
      },
      "outputs": [],
      "source": [
        "merging_vcf_gff(vcfs, gffs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-cc5AflbhXZ"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/vcf_gff/vcfs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAPZ1wJrnIa"
      },
      "outputs": [],
      "source": [
        "!mv *csv.csv /content/gdrive/MyDrive/vcf_gff/v_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV8U8UoObmNd",
        "outputId": "40050fa5-af95-44b0-e305-4ef1dbdc8a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/vcf_gff/v_g\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/vcf_gff/v_g/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkT4UMTiqAUK"
      },
      "outputs": [],
      "source": [
        "!awk '(NR == 1) || (FNR > 1)' *.csv > all_vcf_AgamP4.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFiqS5bxrke5"
      },
      "outputs": [],
      "source": [
        "!mv all_vcf_AgamP4.csv /content/gdrive/MyDrive/vcf_gff/per_samples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw6klz6T-ZzY",
        "outputId": "0da5fd3a-0996-4336-ea57-f0a55a654822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFo3Rt80rN8M",
        "outputId": "523a7718-b410-481b-f30a-f1e97d5b01f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/vcf_gff/per_samples\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/vcf_gff/per_samples/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQdfHkjQswwl"
      },
      "outputs": [],
      "source": [
        "all_samples = pd.read_csv('all_vcf_AgamP4.csv')\n",
        "all_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cDhxeNUtZoH",
        "outputId": "295a0c19-1b55-4e3f-865c-5db88e65d785"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-24216463e1cc>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  all_samples.columns = all_samples.columns.str.replace('_l1l2_mq10.srt.bam', '')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['#CHROM', 'POS', 'REF', 'BD01_S9', 'BD02_S8', 'BD03_S7', 'BP02_S9',\n",
              "       'BP03_S8', 'BP04_S7', 'BU01_S6', 'BU02_S5', 'BU03_S4', 'DA01_S9',\n",
              "       'DA02_S8', 'DA03_S7', 'DD01_S6', 'DD02_S5', 'DD03_S4', 'DP01_S6',\n",
              "       'DP02_S5', 'DP03_S4', 'DU01_S3', 'DU02_S2', 'DU03_S1', 'KIS01_S3',\n",
              "       'KIS02_S2', 'KIS03_S1', 'KIS10_S1', 'KIS6_S3', 'KIS9_S2', 'seq_id',\n",
              "       'source', 'type', 'start', 'end', 'score', 'strand', 'phase',\n",
              "       'attributes', 'ID', 'chrom_pos'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_samples.columns = all_samples.columns.str.replace('_l1l2_mq10.srt.bam', '')\n",
        "all_samples.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGRPzf3Mtjgo"
      },
      "outputs": [],
      "source": [
        "samples = ['BD01_S9', 'BD02_S8', 'BD03_S7', 'BP02_S9',\n",
        "       'BP03_S8', 'BP04_S7', 'BU01_S6', 'BU02_S5', 'BU03_S4', 'DA01_S9',\n",
        "       'DA02_S8', 'DA03_S7', 'DD01_S6', 'DD02_S5', 'DD03_S4', 'DP01_S6',\n",
        "       'DP02_S5', 'DP03_S4', 'DU01_S3', 'DU02_S2', 'DU03_S1', 'KIS01_S3',\n",
        "       'KIS02_S2', 'KIS03_S1', 'KIS10_S1', 'KIS6_S3', 'KIS9_S2']\n",
        "\n",
        "for s in samples:\n",
        "    s_data = all_samples[['#CHROM', 'POS', 'REF', s, 'start', 'end', 'attributes', 'ID', 'chrom_pos']]\n",
        "    change = str('./.')\n",
        "    s_data[s].replace(change, value='NA', inplace=True)\n",
        "    s_data['allele_change'] = s_data['REF'] + '/' + s_data.iloc[:,3].str.split('/').str[1]\n",
        "    s_data['chrom_pos_mut'] = s_data[['chrom_pos', 'allele_change']].astype(str).agg(':'.join, axis=1)\n",
        "    s_data.to_csv(s + \".csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqeLE2EYvOG7"
      },
      "outputs": [],
      "source": [
        "!mv all_vcf_AgamP4.csv /content/gdrive/MyDrive/vcf_gff/v_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew0Kt6v_SIXu"
      },
      "outputs": [],
      "source": [
        "# get the gff and the reference genome file\n",
        "\n",
        "!wget https://vectorbase.org/common/downloads/release-55/AgambiaePEST/gff/data/VectorBase-55_AgambiaePEST.gff\n",
        "!wget https://vectorbase.org/common/downloads/release-55/AgambiaePEST/fasta/data/VectorBase-55_AgambiaePEST_Genome.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlcFMcAPviu5"
      },
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21tQSHIHX9Fa"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# install R packages using the R_packages to_be_installed_permanently.ipynb\n",
        ".libPaths(\"library\")\n",
        "install.packages(\"BiocManager\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        ".libPaths(\"library\")\n",
        "BiocManager::install(c(\"Biostrings\", \"ape\", \"plyr\"))"
      ],
      "metadata": {
        "id": "oiTdMTem-_5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        ".libPaths(\"library\")\n",
        "if (packageVersion(\"devtools\") < 1.6) {\n",
        "  install.packages(\"devtools\")\n",
        "}\n",
        "devtools::install_github(\"hadley/lazyeval\")\n",
        "devtools::install_github(\"hadley/dplyr\")"
      ],
      "metadata": {
        "id": "D0JdGbQUExrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        ".libPaths(\"library\")\n",
        "install.packages(\"data.table\", type = \"source\",\n",
        "    repos = \"https://Rdatatable.gitlab.io/data.table\")"
      ],
      "metadata": {
        "id": "w4rHL94DE3Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anT_KpjOaUZW"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "\n",
        "#Loading library\n",
        "library(ape)\n",
        "library(Biostrings)\n",
        "library(plyr)\n",
        "library(data.table)\n",
        "library(dplyr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOSTGMg2lcMt"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "\n",
        "############################\n",
        "# SETTING UP THE FUNCTIONS #\n",
        "############################\n",
        "\n",
        "# The user doesn't need to do anything in this section. We're just creating the functions that we will need.\n",
        "\n",
        "# Let's write a function to extract useful information from a gene of interest\n",
        "extract.gene.info <- function(agap.number, gff.table, isoform = 'A'){\n",
        "  if (!(isoform %in% LETTERS))\n",
        "    stop('\"isoform\" should be a single capitalised alphabetical letter')\n",
        "  isoform.num <- which(LETTERS == isoform)\n",
        "  gff.focus <- subset(gff.table, grepl(agap.number, attributes) & (!grepl(paste(agap.number, '-[PR][', paste(LETTERS[-isoform.num], collapse = ''), ']', sep = ''), attributes)))\n",
        "  # Get the vector of indices that will reconstitute the gene sequence\n",
        "  cds.ranges <- subset(gff.focus, type == 'CDS')[, c('start', 'end')]\n",
        "  # Get the strand direction for the gene and do a sanity check that only one strand is obtained\n",
        "  strand <- unique(as.character(gff.focus$strand))\n",
        "  if (length(strand) > 1) stop('More than one strand direction detected')\n",
        "  # Same for chromosome\n",
        "  chrom <- unique(as.character(gff.focus$seqid))\n",
        "  if (length(chrom) != 1) stop('The gene should be found on one and only one chromosome.')\n",
        "  # Get the sequence for each of the CDS segments.\n",
        "  sequence.list <- apply(cds.ranges, 1, function(x) substr(genome[[chrom]], x[1], x[2]))\n",
        "  # c() can be used to paste the sequences together, but this doesn't seem to work with do.call (which just\n",
        "  # concatenates everything like the normal c() behaviour), so I don't know how to combine everything together\n",
        "  # except with this clusmy for loop.\n",
        "  full.cds.sequence <- sequence.list[[1]]\n",
        "  for (s in sequence.list[2:length(sequence.list)]){\n",
        "    full.cds.sequence <- c(full.cds.sequence, s)\n",
        "  }\n",
        "  # If necessary, reverse commplement the sequence\n",
        "  if (strand == '-')\n",
        "    full.cds.sequence <- reverseComplement(full.cds.sequence)\n",
        "  # Translate the sequence\n",
        "  full.aa.sequence <- translate(full.cds.sequence)\n",
        "  # Split the cds into codons.\n",
        "  full.codon.list <- sapply(seq(1, length(full.cds.sequence), by = 3), function(i) substr(full.cds.sequence, i, i+2))\n",
        "  # Translate each of those codons\n",
        "  full.aa.list <- sapply(full.codon.list, translate, no.init.codon = T)\n",
        "  # And use that to translate the sequence. This is redundant as we've already done it, but it's just a sanity\n",
        "  # check.\n",
        "  full.aa.sequence.2 <- do.call(c, full.aa.list)\n",
        "  if (full.aa.sequence != full.aa.sequence.2) stop('Codon-by-codon translation didn\\'t match full sequence translation.')\n",
        "\n",
        "  # For a given SNP genomic position, we need to work out in which part of the sequence it is and, if it's a CDS,\n",
        "  # where on the CDS it sits\n",
        "  gene.range <- c(min(gff.focus$start), max(gff.focus$end))\n",
        "  sequence.indices <- rep('intron', gene.range[2] - gene.range[1] + 1)\n",
        "  for (i in 1:nrow(gff.focus)){\n",
        "    feature.type <- as.character(gff.focus[i, 'type'])\n",
        "    if (feature.type %in% c('five_prime_UTR', 'CDS', 'three_prime_UTR'))\n",
        "      sequence.indices[(gff.focus[i, 'start']:gff.focus[i, 'end']) - gene.range[1] + 1] <- feature.type\n",
        "  }\n",
        "  names(sequence.indices) <- as.character(gene.range[1]:gene.range[2])\n",
        "\n",
        "  list(agap = agap.number,\n",
        "       sequence.indices = sequence.indices,\n",
        "       cds.ranges = cds.ranges,\n",
        "       strand = strand,\n",
        "       # To save on memory, store the CDS as character, not DNAStringSet\n",
        "       full.codon.list = sapply(full.codon.list, as.character),\n",
        "       full.aa.list = sapply(full.aa.list, as.character))\n",
        "}\n",
        "\n",
        "# Write a function that will assess the relevance of a SNP, given it's genomic position\n",
        "assess.SNP <- function(snp, gene.data){\n",
        "  snp.id <- strsplit(snp, ':')[[1]]\n",
        "  genome.position <- snp.id[2]\n",
        "  element.type <- gene.data$sequence.indices[genome.position]\n",
        "  if (is.na(element.type))\n",
        "    output <- 'outside'\n",
        "  else if (element.type != 'CDS')\n",
        "    output <- as.character(element.type)\n",
        "  else{\n",
        "    # Which nucleotide of the sequence is it from\n",
        "    cds.indices <- unlist(apply(gene.data$cds.ranges, 1, function(x) x[1]:x[2]))\n",
        "    if (gene.data$strand == '-')\n",
        "      cds.indices <- rev(cds.indices)\n",
        "    nuc.index <- which(cds.indices == genome.position)\n",
        "    codon.index <- ((as.numeric(nuc.index) - 1) %/% 3) + 1\n",
        "    within.codon.position <- ((as.numeric(nuc.index) - 1) %% 3) + 1\n",
        "    ref.codon <- gene.data$full.codon.list[[codon.index]]\n",
        "    ref.aa <- gene.data$full.aa.list[[codon.index]]\n",
        "    ac <- gene.data$allele.counts[(genome.position), paste('counts', 0:3, sep = '')]\n",
        "    if (length(snp.id) > 2) {\n",
        "      alleles = strsplit(snp.id[3], '/')[[1]]\n",
        "      # If the gene is on the negative strand, need to adjust the coding sequence alleles\n",
        "      if (gene.data$strand == '-'){\n",
        "        revcomp.table <- setNames(c('A','C','T','G'), c('T','G','A','C'))\n",
        "        ref.allele <- revcomp.table[alleles[1]]\n",
        "        mut.allele <- revcomp.table[alleles[2]]\n",
        "      }\n",
        "      else {\n",
        "        ref.allele <- alleles[1]\n",
        "        mut.allele <- alleles[2]\n",
        "      }\n",
        "      # Sanity check with ref allel\n",
        "      ref.allele.2 <- substr(ref.codon, within.codon.position, within.codon.position)\n",
        "      if (ref.allele != ref.allele.2) stop('Reference allele sanity check failed.')\n",
        "      # Check whether the mutation results in a change in the amino acid\n",
        "      mut.codon <- replaceAt(DNAString(ref.codon), IRanges(within.codon.position, width = 1), mut.allele)\n",
        "      mut.aa <- translate(mut.codon, no.init.codon = T)\n",
        "      if (as.character(mut.aa) == ref.aa)\n",
        "        output <- list(codon.index, within.codon.position, ref.aa, as.character(mut.aa))\n",
        "      else\n",
        "        output <- list(codon.index, within.codon.position, ref.aa, as.character(mut.aa))\n",
        "    }\n",
        "    else\n",
        "      output <- list(codon.index, within.codon.position, NA, NA)\n",
        "  }\n",
        "  print(paste(output))\n",
        "  invisible(output)\n",
        "}\n",
        "\n",
        "\n",
        "# If you want to assess more than one SNP at once in a given gene, within a table\n",
        "\n",
        "assess.snps.table <- function(table, gff){\n",
        "  table$codon=0\n",
        "  table$codon_position=0\n",
        "  table$ref=0\n",
        "  table$alt=0\n",
        "\n",
        "  for (i in 1:nrow(table)) {\n",
        "    if ((is.na(table[i,'allele_change'])) || (nchar(table[i,'allele_change']) != 3)) # avoiding deletions and insertions\n",
        "      next\n",
        "\n",
        "    a = try(extract.gene.info(table[i,'ID'], gff), silent = TRUE)\n",
        "    b = try(assess.SNP(table[i,'chrom_pos_mut'], a), silent = TRUE)\n",
        "    if (length(b) == 1) {\n",
        "      table[i,'codon'] = b[[1]]\n",
        "    } else {\n",
        "      table[i,'codon'] = b[[1]]\n",
        "      table[i,'codon_position'] = b[[2]]\n",
        "      table[i,'ref'] = b[[3]]\n",
        "      table[i,'alt'] = b[[4]]\n",
        "    }\n",
        "  }\n",
        "  return(table)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw8PO0rrUaHn"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Load the gff. Put the path to your .gff3 file here.\n",
        "gff.path <- 'VectorBase-55_AgambiaePEST.gff'\n",
        "gff <- read.gff(gff.path, GFF3 = T)\n",
        "\n",
        "# Load the genome. Put the path to your genome here.\n",
        "genome.path <- 'VectorBase-55_AgambiaePEST_Genome.fasta'\n",
        "genome <- readDNAStringSet(genome.path)\n",
        "names(genome) <- sub(' .*', '', names(genome))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Jidkh5Up0-"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "\n",
        "list.files(\"/content/gdrive/MyDrive/vcf_gff/per_samples\")\n",
        "\n",
        "fileNames<-Sys.glob(\"*.csv\")\n",
        "\n",
        "for (file in fileNames) {\n",
        "\n",
        "  table <- read.csv(file, check.names = F, na.strings=c(\"\",\"NA\"))\n",
        "  aa_change <- assess.snps.table(table,gff)\n",
        "  savename <- paste0(\"aa_changes_\", colnames(aa_change)[4], \".csv\")\n",
        "  write.table(aa_change, savename, quote=FALSE, row.names = FALSE, col.names = TRUE, sep='\\t')\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSzgsbua5L-n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMC03fd3rfhkuCLmi+yH0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}